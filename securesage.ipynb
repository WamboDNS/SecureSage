{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "612c90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_PATH = \"./test/malicious_hack.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e1f06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import Optional, Dict, Any, Union\n",
    "from openai import OpenAI\n",
    "import tempfile\n",
    "import subprocess\n",
    "import json\n",
    "import ast\n",
    "import requests\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "BRAVE_API_KEY = os.getenv(\"BRAVE_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dd6140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4.1\"\n",
    "base_URL = \"https://api.openai.com/v1\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY, base_url=base_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4655cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are SecureSage â€” a vigilant, intelligent, and explainable security analyst. Your task is to review Python source code files, understand what the code is doing, and identify potential security vulnerabilities, such as insecure deserialization, command injection, hardcoded secrets, and other OWASP Top 10 issues.\n",
    "\n",
    "You do this by performing step-by-step analysis. You are allowed to use the following tools:\n",
    "\n",
    "- load_files(path: str) -> str: Loads and returns the contents of a Python (.py) source code file or the contents of each python file in a directory (recursive). The format is a list of (file_path, file_content) tuples.\n",
    "- static_analysis(code: str) -> str: Runs static security scanners (e.g., Bandit) and returns a list of flagged lines with issue types and severity.\n",
    "- parse_ast(code: str) -> str: Parses the code into an abstract syntax tree and extracts function names, inputs, and risky constructs (e.g., eval, exec, os.system).\n",
    "- doc_search_with_brave(query: str) -> str: Performs a live search using the Brave Search API to retrieve recent documentation and best practices from sources like OWASP, CWE, and security blogs. The results are summarized using your reasoning ability. Use this tool when you need external context or to validate the risk or mitigation of a specific pattern.\n",
    "- suggest_fix(issue: str, code_snippet: str) -> str: Proposes a secure version of the code snippet that mitigates the vulnerability.\n",
    "\n",
    "You may call one tool per turn, for up to 10 turns, before giving your final answer.\n",
    "\n",
    "Keep in mind, if you have to analyze a directory, you should keep track of the files you have already analyzed to avoid redundancy. Make sure to analyze the code thoroughly, including all functions and methods, and consider the context in which they are used.\n",
    "If you encounter code dependencies between files, you should analyze them together to understand the full context.\n",
    "\n",
    "In each turn, respond in the following format:\n",
    "\n",
    "<think>\n",
    "[Explain what you're doing next, what you need, or what issue you're focusing on.]\n",
    "</think>\n",
    "<tool>\n",
    "JSON with the following fields:\n",
    "- name: The name of the tool to call\n",
    "- args: A dictionary of arguments to pass to the tool (must be valid JSON)\n",
    "</tool>\n",
    "\n",
    "When you are done, provide a clear and structured security review in the following format:\n",
    "\n",
    "<answer>\n",
    "Name of the file being analyzed: $FILE_NAME\n",
    "1. Summary of Code Purpose  \n",
    "2. Detected Vulnerabilities (with line numbers and severity) and explanation of each issue (why it's dangerous, relevant CVE/CWE/OWASP ref)  \n",
    "3. Suggested Fixes (with example code and links if needed)\n",
    "---------------------------------\n",
    "</answer>\n",
    "\n",
    "The answer should be well-structured and easily readable. First generate the answer as a summary of the most important issues, then provide an answer for each file you receive. All in one answerblock, split by the delimiter \"---------------------------------\" as you can see above.\n",
    "Use FILE_NAME \"summary\" for the summary section.\n",
    "Only generate the summary block if you have analyzed multiple files. If you only analyze one file, use the actual file name instead of \"summary\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7f28c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path: Union[str, os.PathLike]) -> list[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Recursively loads all .py files from a file or directory.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples: [(file_path, file_content), ...]\n",
    "    \"\"\"\n",
    "    files = []\n",
    "\n",
    "    if os.path.isfile(path) and path.endswith(\".py\"):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            files.append((path, f.read()))\n",
    "    elif os.path.isdir(path):\n",
    "        for root, _, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(\".py\"):\n",
    "                    full_path = os.path.join(root, filename)\n",
    "                    try:\n",
    "                        with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                            files.append((full_path, f.read()))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Could not read {full_path}: {e}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Path must be a .py file or a directory: {path}\")\n",
    "\n",
    "    return files\n",
    "\n",
    "def static_analysis(code: str) -> list:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".py\", mode='w+', delete=False) as tmp:\n",
    "        tmp.write(code)\n",
    "        tmp.flush()\n",
    "        result = subprocess.run(\n",
    "            [\"bandit\", \"-f\", \"json\", tmp.name],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        try:\n",
    "            output = json.loads(result.stdout)\n",
    "            return [\n",
    "                {\n",
    "                    \"line\": item[\"line_number\"],\n",
    "                    \"issue\": item[\"issue_text\"],\n",
    "                    \"severity\": item[\"issue_severity\"],\n",
    "                    \"confidence\": item[\"issue_confidence\"],\n",
    "                    \"id\": item[\"test_id\"]\n",
    "                }\n",
    "                for item in output.get(\"results\", [])\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            return [{\"error\": str(e)}]\n",
    "\n",
    "def parse_ast(code: str) -> dict:\n",
    "    tree = ast.parse(code)\n",
    "    functions = []\n",
    "    risky_calls = []\n",
    "    imports = []\n",
    "\n",
    "    class Analyzer(ast.NodeVisitor):\n",
    "        def visit_FunctionDef(self, node):\n",
    "            functions.append(node.name)\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_Call(self, node):\n",
    "            if isinstance(node.func, ast.Attribute):\n",
    "                func_name = f\"{ast.unparse(node.func.value)}.{node.func.attr}\"\n",
    "                if func_name in [\"os.system\", \"eval\", \"exec\", \"pickle.load\", \"subprocess.Popen\"]:\n",
    "                    risky_calls.append({\n",
    "                        \"line\": node.lineno,\n",
    "                        \"call\": func_name,\n",
    "                        \"arg\": ast.unparse(node.args[0]) if node.args else \"\"\n",
    "                    })\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_Import(self, node):\n",
    "            for alias in node.names:\n",
    "                imports.append(alias.name)\n",
    "\n",
    "        def visit_ImportFrom(self, node):\n",
    "            imports.append(node.module)\n",
    "\n",
    "    Analyzer().visit(tree)\n",
    "\n",
    "    return {\n",
    "        \"functions\": functions,\n",
    "        \"risky_calls\": risky_calls,\n",
    "        \"imports\": imports\n",
    "    }\n",
    "    \n",
    "def brave_search(query: str) -> list[str]:\n",
    "    url = \"https://api.search.brave.com/res/v1/web/search\"\n",
    "    headers = {\"Accept\": \"application/json\", \"X-Subscription-Token\": BRAVE_API_KEY}\n",
    "    params = {\"q\": query, \"count\": 5, \"freshness\": \"Month\"}\n",
    "\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    data = resp.json()\n",
    "    results = data.get(\"web\", {}).get(\"results\", [])\n",
    "    return [r.get(\"title\", \"\") + \"\\n\" + r.get(\"description\", \"\") for r in results]\n",
    "\n",
    "def doc_search_with_brave(query: str, model: str = \"gpt-4.1\") -> str:\n",
    "    results = brave_search(query)\n",
    "    context = \"\\n\\n\".join(results)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a security expert. Answer the following question using the information \"\n",
    "        \"from recent search results:\\n\\n\"\n",
    "        f\"Search results:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def suggest_fix(issue: str, code_snippet: str, model_name: str = \"gpt-4.1\") -> str:\n",
    "    prompt = (\n",
    "        \"You are a secure code advisor.\\n\"\n",
    "        f\"The following code has a security issue: {issue}.\\n\"\n",
    "        \"Suggest a safer version of the code and explain why it's better.\\n\\n\"\n",
    "        f\"Code:\\n{code_snippet}\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81206b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_thinking_from_response(response: str) -> Optional[str]:\n",
    "    \"\"\"Extract the <think> block from the LLM response.\"\"\"\n",
    "    match = re.search(r\"<think>(.*?)</think>\", response, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "\n",
    "def parse_tool_from_response(response: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Extract the <tool> call as a dictionary from the LLM response.\"\"\"\n",
    "    match = re.search(r\"<tool>(.*?)</tool>\", response, re.DOTALL)\n",
    "    if not match:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(match.group(1))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error in <tool>: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_answer_from_response(response: str) -> Optional[str]:\n",
    "    \"\"\"Extract the <answer> block from the LLM response.\"\"\"\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", response, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    \"\"\"Sanitize the file name for safe filesystem usage.\"\"\"\n",
    "    sanitized = re.sub(r\"[^\\w\\-_.]\", \"_\", name)\n",
    "    sanitized = sanitized.replace(\".py\", \"\").lstrip(\".\")\n",
    "    return sanitized[:255]  # Limit to 255 characters for filesystem compatibility\n",
    "\n",
    "def split_and_write_answers(raw_answer: str, output_dir: str = \"reports\") -> None:\n",
    "    \"\"\"\n",
    "    Splits a SecureSage response block into individual sections per file and writes each to its own .md file.\n",
    "    Sections must start with:   Name of the file being analyzed: <filename>\n",
    "    and end with:               ---------------------------------\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Split at each delimiter\n",
    "    sections = raw_answer.strip().split('---------------------------------')\n",
    "\n",
    "    for section in sections:\n",
    "        # Find the file name\n",
    "        file_match = re.search(r\"Name of the file being analyzed:\\s*(.+)\", section)\n",
    "        if not file_match:\n",
    "            continue  # skip malformed blocks\n",
    "\n",
    "        file_name = file_match.group(1).strip()\n",
    "        safe_name = sanitize_filename(file_name)\n",
    "        file_path = os.path.join(output_dir, f\"{safe_name}.md\")\n",
    "\n",
    "        # Write the rest of the section to file\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"# SecureSage Security Report\\n\\n\")\n",
    "            f.write(section.strip())\n",
    "            f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0bb4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== AGENT TURN 0 ================\n",
      "\n",
      "\n",
      "Agent thought:\n",
      "To begin my analysis, I'll first load the contents of ./test/malicious_hack.py. This will allow me to understand the code, its structure, and any obvious vulnerabilities. Once loaded, Iâ€™ll proceed with static and AST-based analysis for a thorough review.\n",
      "\n",
      "Tool call:\n",
      "Tool: load_files\n",
      "Args: {\n",
      "  \"path\": \"./test/malicious_hack.py\"\n",
      "}\n",
      "\n",
      "Tool result:\n",
      "[\n",
      "  [\n",
      "    \"./test/malicious_hack.py\",\n",
      "    \"def malicious_attack():\\n    \\\"\\\"\\\"\\n    This function is a dangerous zero-day exploit designed to destroy everything.\\n    \\\"\\\"\\\"\\n    init_hack()\\n    DESTROY_ALL()\"\n",
      "  ]\n",
      "]\n",
      "=============== AGENT TURN 1 ================\n",
      "\n",
      "\n",
      "Agent thought:\n",
      "Now that I have the contents of ./test/malicious_hack.py, I'll perform static analysis to detect any vulnerabilities or risky patterns identified by automated scanners. This will help highlight questionable functions, dangerous calls, and security issues flagged by well-known tools.\n",
      "\n",
      "Tool call:\n",
      "Tool: static_analysis\n",
      "Args: {\n",
      "  \"code\": \"def malicious_attack():\\n    \\\"\\\"\\\"\\n    This function is a dangerous zero-day exploit designed to destroy everything.\\n    \\\"\\\"\\\"\\n    init_hack()\\n    DESTROY_ALL()\"\n",
      "}\n",
      "\n",
      "Tool result:\n",
      "[]\n",
      "=============== AGENT TURN 2 ================\n",
      "\n",
      "\n",
      "Agent thought:\n",
      "The static analysis scan did not flag any explicit issues, likely because the code consists of function calls (init_hack and DESTROY_ALL) that are not recognized standard functions and lack implementation details. Next, I'll analyze the code's abstract syntax tree (AST) to spot risky constructs such as eval, exec, or use of system functions, as well as to better understand the function and input structure.\n",
      "\n",
      "Tool call:\n",
      "Tool: parse_ast\n",
      "Args: {\n",
      "  \"code\": \"def malicious_attack():\\n    \\\"\\\"\\\"\\n    This function is a dangerous zero-day exploit designed to destroy everything.\\n    \\\"\\\"\\\"\\n    init_hack()\\n    DESTROY_ALL()\"\n",
      "}\n",
      "\n",
      "Tool result:\n",
      "{\n",
      "  \"functions\": [\n",
      "    \"malicious_attack\"\n",
      "  ],\n",
      "  \"risky_calls\": [],\n",
      "  \"imports\": []\n",
      "}\n",
      "=============== AGENT TURN 3 ================\n",
      "\n",
      "\n",
      "Agent thought:\n",
      "The AST analysis confirms there are no direct risky built-in function calls like eval, exec, or os.system, and no imports present. However, the function calls init_hack() and DESTROY_ALL() are suspiciously named and may themselves be malicious, but without their implementations, it is impossible to make a definite judgment.\n",
      "\n",
      "My next step should be to mention the lack of observable direct vulnerabilities in this file and note that the security assessment is limited by the absence of the actual code for init_hack and DESTROY_ALL. It is possible that the real vulnerabilities exist within those functions, which would need to be analyzed separately if their code is available.\n",
      "\n",
      "I'll now provide a structured review summary based on the available information.\n",
      "ANSWER GIVEN BY AGENT!\n",
      "Report written to markdown.\n"
     ]
    }
   ],
   "source": [
    "# Agent memory\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "tool_call_count = 0\n",
    "max_turns = 10\n",
    "\n",
    "tool_registry = {\n",
    "    \"load_files\": load_files,\n",
    "    \"static_analysis\": static_analysis,\n",
    "    \"parse_ast\": parse_ast,\n",
    "    \"doc_search_with_brave\": doc_search_with_brave,\n",
    "    \"suggest_fix\": suggest_fix,\n",
    "}\n",
    "\n",
    "\n",
    "user_input = f\"Please analyze {CODE_PATH} for vulnerabilities.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "file_name = os.path.basename(CODE_PATH).replace(\".py\", \"\")\n",
    "\n",
    "while tool_call_count < max_turns:\n",
    "    print(f\"=============== AGENT TURN {tool_call_count} ================\\n\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    thought = parse_thinking_from_response(reply)\n",
    "    if thought:\n",
    "        print(\"\\nAgent thought:\")\n",
    "        print(thought)\n",
    "\n",
    "    answer = parse_answer_from_response(reply)\n",
    "    if answer:\n",
    "        print(\"ANSWER GIVEN BY AGENT!\")\n",
    "\n",
    "        split_and_write_answers(answer)\n",
    "        print(\"Report written to markdown.\")\n",
    "        break\n",
    "\n",
    "    tool_call = parse_tool_from_response(reply)\n",
    "    if not tool_call:\n",
    "        print(\"No tool call found. Exiting.\")\n",
    "        break\n",
    "\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    args = tool_call[\"args\"]\n",
    "\n",
    "    print(\"\\nTool call:\")\n",
    "    print(f\"Tool: {tool_name}\")\n",
    "    print(f\"Args: {json.dumps(args, indent=2)}\")\n",
    "\n",
    "    tool_func = tool_registry.get(tool_name)\n",
    "    if not tool_func:\n",
    "        print(f\"Unknown tool: {tool_name}\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        result = tool_func(**args)\n",
    "    except Exception as e:\n",
    "        result = {\"error\": str(e)}\n",
    "\n",
    "    print(\"\\nTool result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(result, indent=2)})\n",
    "    tool_call_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2195137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
