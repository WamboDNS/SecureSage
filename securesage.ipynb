{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "612c90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_PATH = \"./example_code/malicious_hack.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e1f06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import Optional, Dict, Any, Union, List, Tuple\n",
    "from openai import OpenAI\n",
    "import tempfile\n",
    "import subprocess\n",
    "import json\n",
    "import ast\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "BRAVE_API_KEY = os.getenv(\"BRAVE_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7dd6140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4.1\"\n",
    "base_URL = \"https://api.openai.com/v1\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY, base_url=base_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4655cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are SecureSage â€” a vigilant, intelligent, and explainable security analyst. Your task is to review project files, understand what the code and configurations are doing, and identify potential security vulnerabilities. This includes issues in Python code (like insecure deserialization, command injection, hardcoded secrets, OWASP Top 10) and potential misconfigurations or secrets in other file types. You also check for known vulnerabilities in project dependencies.\n",
    "It is very important that you try to identify all vulnerabilities and not only the most obvious ones. Do not only look for vulnerabilities of the categories mentioned above!\n",
    "\n",
    "You do this by performing step-by-step analysis. You are allowed to use the following tools:\n",
    "\n",
    "- load_files(path: str) -> str: Loads and returns the contents of ALL non-hidden files from a specified file or recursively from a directory. The format is a list of (file_path, file_content) tuples. Content for binary files or files too large might be a placeholder. Be mindful of the content type of each file when deciding which other tools to use.\n",
    "- static_analysis(code: str) -> str: Runs static security scanners (e.g., Bandit) on PYTHON CODE and returns a list of flagged lines with issue types and severity. CRITICAL: Only pass the content of Python (.py) files to this tool. Do NOT pass content from non-Python files.\n",
    "- parse_ast(code: str) -> str: Parses PYTHON CODE into an abstract syntax tree and extracts function names, inputs, and risky constructs (e.g., eval, exec, os.system). CRITICAL: Only pass the content of Python (.py) files to this tool. Do NOT pass content from non-Python files.\n",
    "- check_dependencies(project_path: str) -> str: Scans project dependency files (e.g., requirements.txt, poetry.lock, etc.) using 'pip-audit' to find known vulnerabilities in third-party packages. The 'project_path' should be the root directory of the project that contains these dependency files. If the initial analysis target was a directory, use that directory as 'project_path'. If the initial analysis target was a single file, use its *containing directory* as 'project_path' for this tool. Returns a JSON string with findings.\n",
    "- doc_search_with_brave(query: str) -> str: Performs a live search using the Brave Search API to retrieve recent documentation and best practices from sources like OWASP, CWE, and security blogs. The results are summarized using your reasoning ability. Use this tool when you need external context or to validate the risk or mitigation of a specific pattern identified in ANY file type.\n",
    "- suggest_fix(issue: str, code_snippet: str) -> str: Proposes a secure version of a code snippet that mitigates a vulnerability. This is primarily for Python code, but can be adapted for configuration files if the issue is simple (e.g., removing a hardcoded secret). Clearly state if the fix applies to a non-Python file.\n",
    "\n",
    "You may call one tool per turn, for up to 10 turns, before giving your final answer.\n",
    "\n",
    "When analyzing a directory with multiple files, or a single file that might be part of a larger project:\n",
    "- First, load all files using `load_files` to get a comprehensive overview of the project.\n",
    "- Review the list of loaded files and their paths. For each file:\n",
    "    - If it's a Python file (.py), plan to use `static_analysis` and `parse_ast` on its content.\n",
    "    - If it's a known dependency file (requirements.txt, poetry.lock, etc.), remember its path for use with `check_dependencies`.\n",
    "    - For ALL file types (including configurations like .json, .yaml, .ini, .toml, Dockerfiles, shell scripts, etc.), manually review their content for hardcoded secrets, weak configurations, sensitive data exposure, or any other security-relevant information. Use `doc_search_with_brave` if you need more context on a specific technology or pattern found.\n",
    "- Determine the effective 'project_path' for dependency checking:\n",
    "    - If the input `CODE_PATH` was a directory, that directory is the 'project_path'.\n",
    "    - If the input `CODE_PATH` was a file path, its containing directory should be considered for `check_dependencies`.\n",
    "- Pay close attention to how different components (Python files, configuration files, scripts) might interact to create vulnerabilities.\n",
    "- Trace data flow across files and components.\n",
    "- Your analysis should be thorough.\n",
    "\n",
    "In each turn, respond in the following format:\n",
    "\n",
    "<think>\n",
    "[Explain what you're doing next, what you need, or what issue you're focusing on. Explicitly state which file(s) you are examining and if you intend to pass specific file content to a tool, confirm its type is appropriate for that tool (e.g., \"Passing content of 'utils.py' to static_analysis as it is Python code.\" or \"Reviewing 'config.json' for hardcoded secrets.\"). If dependency files are present, explicitly state the 'project_path' you intend to use for `check_dependencies`.]\n",
    "</think>\n",
    "<tool>\n",
    "JSON with the following fields:\n",
    "- name: The name of the tool to call\n",
    "- args: A dictionary of arguments to pass to the tool (must be valid JSON)\n",
    "</tool>\n",
    "\n",
    "When you are done, provide a clear and structured security review in the following format:\n",
    "\n",
    "<answer>\n",
    "Name of the file being analyzed: $FILE_NAME\n",
    "1. Summary of File/Code Purpose (If $FILE_NAME is \"summary\", this should be an overall project summary)\n",
    "2. Detected Vulnerabilities (with file paths, line numbers if applicable, and severity) and explanation of each issue (why it's dangerous, relevant CVE/CWE/OWASP ref). Clearly distinguish between issues in Python code versus issues in configuration or other file types. Explicitly mention if a vulnerability spans multiple files/components. Include a section for \"Dependency Vulnerabilities\" if `check_dependencies` was used and found issues.\n",
    "3. Suggested Fixes (with example code/configuration and links if possible and helpful). Specify which file the fix applies to.\n",
    "---------------------------------\n",
    "</answer>\n",
    "\n",
    "The answer should be well-structured and easily readable.\n",
    "If analyzing multiple files/a directory, first generate a \"summary\" report. This summary should highlight:\n",
    "  - The overall purpose of the project/directory.\n",
    "  - The most critical vulnerabilities found across ALL file types.\n",
    "  - A summary of any known vulnerabilities found in third-party dependencies.\n",
    "  - General recommendations or patterns observed.\n",
    "Then, provide a detailed report for each *significant* file analyzed (prioritize Python files and any non-Python files where issues were found). All reports (summary and per-file) should be in one answer block, separated by \"---------------------------------\".\n",
    "Use the name \"summary\" for the summary section. If only a single file was analyzed, omit the summary block.\n",
    "</answer>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f7f28c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path: Union[str, os.PathLike]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Recursively loads all non-hidden files from a file or directory.\n",
    "    Attempts to read files as UTF-8 text. If a file cannot be decoded,\n",
    "    a placeholder message is returned as its content.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples: [(file_path, file_content), ...]\n",
    "    \"\"\"\n",
    "    files_to_load = []\n",
    "    normalized_path = os.path.normpath(path)\n",
    "\n",
    "    def read_file_content(file_path: str) -> str:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            return f\"[Cannot decode file as UTF-8 text: {os.path.basename(file_path)} - likely a binary file]\"\n",
    "        except Exception as e:\n",
    "            return f\"[Error reading file {os.path.basename(file_path)}: {e}]\"\n",
    "\n",
    "    if os.path.isfile(normalized_path):\n",
    "        content = read_file_content(normalized_path)\n",
    "        files_to_load.append((normalized_path, content))\n",
    "\n",
    "    elif os.path.isdir(normalized_path):\n",
    "        for root, dirs, filenames in os.walk(normalized_path):\n",
    "            # Filter out hidden directories from further traversal\n",
    "            dirs[:] = [d for d in dirs if not d.startswith('.')]\n",
    "            \n",
    "            for filename in filenames:\n",
    "                if filename.startswith('.'):  # Skip hidden files\n",
    "                    continue\n",
    "                \n",
    "                full_path = os.path.join(root, filename)\n",
    "                if os.path.isfile(full_path): # Ensure it's a file (os.walk can list other things)\n",
    "                    content = read_file_content(full_path)\n",
    "                    files_to_load.append((full_path, content))\n",
    "    else:\n",
    "        raise ValueError(f\"Path must be a valid file or a directory: {normalized_path}\")\n",
    "\n",
    "    if not files_to_load and (os.path.isfile(normalized_path) or os.path.isdir(normalized_path)):\n",
    "        # This might occur if a directory is empty or contains only hidden files.\n",
    "        print(f\"Info: No non-hidden files were loaded from '{normalized_path}'.\")\n",
    "\n",
    "    return files_to_load\n",
    "\n",
    "def static_analysis(code: str) -> list:\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".py\", mode='w+', delete=False) as tmp:\n",
    "        tmp.write(code)\n",
    "        tmp.flush()\n",
    "        result = subprocess.run(\n",
    "            [\"bandit\", \"-f\", \"json\", tmp.name],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        try:\n",
    "            output = json.loads(result.stdout)\n",
    "            return [\n",
    "                {\n",
    "                    \"line\": item[\"line_number\"],\n",
    "                    \"issue\": item[\"issue_text\"],\n",
    "                    \"severity\": item[\"issue_severity\"],\n",
    "                    \"confidence\": item[\"issue_confidence\"],\n",
    "                    \"id\": item[\"test_id\"]\n",
    "                }\n",
    "                for item in output.get(\"results\", [])\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            return [{\"error\": str(e)}]\n",
    "\n",
    "def parse_ast(code: str) -> dict:\n",
    "    tree = ast.parse(code)\n",
    "    functions = []\n",
    "    risky_calls = []\n",
    "    imports = []\n",
    "\n",
    "    class Analyzer(ast.NodeVisitor):\n",
    "        def visit_FunctionDef(self, node):\n",
    "            functions.append(node.name)\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_Call(self, node):\n",
    "            if isinstance(node.func, ast.Attribute):\n",
    "                func_name = f\"{ast.unparse(node.func.value)}.{node.func.attr}\"\n",
    "                if func_name in [\"os.system\", \"eval\", \"exec\", \"pickle.load\", \"subprocess.Popen\"]:\n",
    "                    risky_calls.append({\n",
    "                        \"line\": node.lineno,\n",
    "                        \"call\": func_name,\n",
    "                        \"arg\": ast.unparse(node.args[0]) if node.args else \"\"\n",
    "                    })\n",
    "            self.generic_visit(node)\n",
    "\n",
    "        def visit_Import(self, node):\n",
    "            for alias in node.names:\n",
    "                imports.append(alias.name)\n",
    "\n",
    "        def visit_ImportFrom(self, node):\n",
    "            imports.append(node.module)\n",
    "\n",
    "    Analyzer().visit(tree)\n",
    "\n",
    "    return {\n",
    "        \"functions\": functions,\n",
    "        \"risky_calls\": risky_calls,\n",
    "        \"imports\": imports\n",
    "    }\n",
    "    \n",
    "def brave_search(query: str) -> list[str]:\n",
    "    url = \"https://api.search.brave.com/res/v1/web/search\"\n",
    "    headers = {\"Accept\": \"application/json\", \"X-Subscription-Token\": BRAVE_API_KEY}\n",
    "    params = {\"q\": query, \"count\": 5, \"freshness\": \"Month\"}\n",
    "\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    data = resp.json()\n",
    "    results = data.get(\"web\", {}).get(\"results\", [])\n",
    "    return [r.get(\"title\", \"\") + \"\\n\" + r.get(\"description\", \"\") for r in results]\n",
    "\n",
    "def doc_search_with_brave(query: str, model: str = \"gpt-4.1\") -> str:\n",
    "    results = brave_search(query)\n",
    "    context = \"\\n\\n\".join(results)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a security expert. Answer the following question using the information \"\n",
    "        \"from recent search results:\\n\\n\"\n",
    "        f\"Search results:\\n{context}\\n\\n\"\n",
    "        f\"Question: {query}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "def suggest_fix(issue: str, code_snippet: str, model_name: str = \"gpt-4.1\") -> str:\n",
    "    prompt = (\n",
    "        \"You are a secure code advisor.\\n\"\n",
    "        f\"The following code has a security issue: {issue}.\\n\"\n",
    "        \"Suggest a safer version of the code and explain why it's better.\\n\\n\"\n",
    "        f\"Code:\\n{code_snippet}\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def check_dependencies(project_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Checks project dependencies for known vulnerabilities using pip-audit.\n",
    "    Assumes a modern pip-audit installation that supports '--json'.\n",
    "    Uses 'sys.executable -m pip_audit' to ensure the correct environment's pip-audit.\n",
    "\n",
    "    Args:\n",
    "        project_path: The root path of the project to scan.\n",
    "\n",
    "    Returns:\n",
    "        A JSON string summarizing found vulnerabilities or a status message.\n",
    "    \"\"\"\n",
    "    resolved_project_path = os.path.abspath(project_path)\n",
    "\n",
    "    audit_target_description = \"\"\n",
    "    pip_audit_explicit_args = [] # For -r <file>\n",
    "    run_in_project_dir = False\n",
    "    target_file_path = None \n",
    "\n",
    "    potential_files = [\n",
    "        (\"poetry.lock\", True, False),\n",
    "        (\"pdm.lock\", True, False),\n",
    "        (\"requirements.lock\", False, True),\n",
    "        (\"requirements.txt\", False, True),\n",
    "        (\"pyproject.toml\", True, False),\n",
    "    ]\n",
    "\n",
    "    for P_FILENAME, P_RUN_IN_DIR, P_EXPLICIT_ARG in potential_files:\n",
    "        current_file_path = os.path.join(resolved_project_path, P_FILENAME)\n",
    "        if os.path.exists(current_file_path):\n",
    "            audit_target_description = f\"Found {P_FILENAME}\"\n",
    "            target_file_path = current_file_path\n",
    "            run_in_project_dir = P_RUN_IN_DIR\n",
    "            if P_EXPLICIT_ARG:\n",
    "                pip_audit_explicit_args = [\"-r\", target_file_path]\n",
    "            break\n",
    "\n",
    "    if not audit_target_description:\n",
    "        return json.dumps({\"status\": f\"No common dependency or lock files found in project path '{project_path}'. List checked: poetry.lock, pdm.lock, requirements.lock/txt, pyproject.toml.\"})\n",
    "\n",
    "    results = []\n",
    "    cwd_for_audit = resolved_project_path if run_in_project_dir else os.getcwd() \n",
    "\n",
    "    command = [\n",
    "        sys.executable,\n",
    "        \"-m\", \"pip_audit\",\n",
    "        \"--progress-spinner\", \"off\",\n",
    "        \"--no-deps\", \"--disable-pip\"\n",
    "    ]\n",
    "    command.extend(pip_audit_explicit_args) # Add \"-r <file>\" if needed\n",
    "\n",
    "    final_command_used_str = \" \".join(command)\n",
    "\n",
    "    source_name_for_report = os.path.basename(target_file_path) if target_file_path else f\"Project Directory Scan ({project_path})\"\n",
    "\n",
    "    try:\n",
    "        process = subprocess.run(\n",
    "            command,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            cwd=cwd_for_audit,\n",
    "            check=False\n",
    "        )\n",
    "        raw_output = process.stdout.strip()\n",
    "        stderr_output = process.stderr.strip()\n",
    "        return_code = process.returncode\n",
    "\n",
    "        if return_code != 0:\n",
    "            if not raw_output: # Error likely\n",
    "                results.append({\n",
    "                    \"source\": source_name_for_report,\n",
    "                    \"error\": f\"pip-audit command failed with exit code {return_code}.\",\n",
    "                    \"stderr\": stderr_output,\n",
    "                    \"stdout\": raw_output, # Should be empty\n",
    "                    \"command_used\": final_command_used_str\n",
    "                })\n",
    "                return json.dumps(results, indent=2)\n",
    "\n",
    "        if not raw_output: # No vulnerabilities found and command was successful (return_code 0)\n",
    "            results.append({\n",
    "                \"source\": source_name_for_report,\n",
    "                \"status\": \"No vulnerabilities found.\",\n",
    "                \"command_used\": final_command_used_str\n",
    "            })\n",
    "        else:\n",
    "            try: \n",
    "                vulnerabilities_data = json.loads(raw_output)\n",
    "                formatted_vulns = []\n",
    "                for dep_info in vulnerabilities_data: \n",
    "                    if \"vulns\" in dep_info and dep_info[\"vulns\"]:\n",
    "                        for vuln in dep_info[\"vulns\"]:\n",
    "                            formatted_vulns.append({\n",
    "                                \"package\": dep_info[\"name\"],\n",
    "                                \"version\": dep_info[\"version\"],\n",
    "                                \"id\": vuln[\"id\"],\n",
    "                                \"description\": vuln[\"description\"],\n",
    "                                \"fix_versions\": vuln.get(\"fix_versions\", [])\n",
    "                            })\n",
    "                if formatted_vulns:\n",
    "                    results.append({\n",
    "                        \"source\": source_name_for_report,\n",
    "                        \"vulnerabilities\": formatted_vulns,\n",
    "                        \"command_used\": final_command_used_str\n",
    "                    })\n",
    "                else:\n",
    "                    results.append({\n",
    "                        \"source\": source_name_for_report,\n",
    "                        \"status\": \"No vulnerabilities found (parsed empty or no vulns in JSON).\",\n",
    "                        \"command_used\": final_command_used_str\n",
    "                    })\n",
    "            except json.JSONDecodeError as e:\n",
    "                 results.append({\n",
    "                    \"source\": source_name_for_report,\n",
    "                    \"error\": f\"Failed to parse pip-audit JSON output: {e}\",\n",
    "                    \"raw_output_preview\": raw_output[:1000],\n",
    "                    \"stderr\": stderr_output,\n",
    "                    \"return_code\": return_code,\n",
    "                    \"command_used\": final_command_used_str\n",
    "                })\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\"error\": f\"Failed to execute pip-audit. '{sys.executable} -m pip_audit' not found or pip_audit module missing in this environment. Please ensure pip-audit is installed in the environment: {sys.prefix}\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"An unexpected error occurred in check_dependencies: {e}\", \"command_attempted\": final_command_used_str})\n",
    "\n",
    "    return json.dumps(results, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81206b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_thinking_from_response(response: str) -> Optional[str]:\n",
    "    \"\"\"Extract the <think> block from the LLM response.\"\"\"\n",
    "    match = re.search(r\"<think>(.*?)</think>\", response, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "\n",
    "def parse_tool_from_response(response: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Extract the <tool> call as a dictionary from the LLM response.\"\"\"\n",
    "    match = re.search(r\"<tool>(.*?)</tool>\", response, re.DOTALL)\n",
    "    if not match:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(match.group(1))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing error in <tool>: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_answer_from_response(response: str) -> Optional[str]:\n",
    "    \"\"\"Extract the <answer> block from the LLM response.\"\"\"\n",
    "    match = re.search(r\"<answer>(.*?)</answer>\", response, re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    \"\"\"Sanitize the file name for pretty and safe filesystem usage.\n",
    "    Generates names like 'SecureSage-Report-your-file-name.md' (extension added later).\n",
    "    \"\"\"\n",
    "    \n",
    "    prefix = \"SecureSage-Report-\"\n",
    "    \n",
    "    # Handle special \"summary\" case (case-insensitive)\n",
    "    if name.lower() == \"summary\":\n",
    "        base_name_intermediate = \"summary\"\n",
    "    else:\n",
    "        processed_name = name\n",
    "        while processed_name.startswith((\"./\", \".\\\\\")):\n",
    "            processed_name = processed_name[2:]\n",
    "        while processed_name.startswith((\"../\", \"..\\\\\")):\n",
    "            processed_name = processed_name[3:]\n",
    "            \n",
    "        # Replace directory separators with hyphens\n",
    "        base_name_intermediate = processed_name.replace(\"/\", \"-\").replace(\"\\\\\", \"-\")\n",
    "        \n",
    "        base_name_intermediate = base_name_intermediate.split(\".\")[0]\n",
    "            \n",
    "    base_name_slug = base_name_intermediate.lower()\n",
    "    base_name_slug = re.sub(r\"[^a-z0-9\\-]+\", \"-\", base_name_slug)\n",
    "    base_name_slug = re.sub(r\"-+\", \"-\", base_name_slug)\n",
    "    base_name_slug = base_name_slug.strip(\"-\")\n",
    "\n",
    "    if not base_name_slug:\n",
    "        base_name_slug = \"untitled-report\"\n",
    "        \n",
    "    full_sanitized_name = f\"{prefix}{base_name_slug}\"\n",
    "    return full_sanitized_name[:250]\n",
    "\n",
    "def split_and_write_answers(raw_answer: str, output_dir: str = \"reports\") -> None:\n",
    "    \"\"\"\n",
    "    Splits a SecureSage response block into individual sections per file and writes each to its own .md file.\n",
    "    Sections must start with:   Name of the file being analyzed: <filename>\n",
    "    and end with:               ---------------------------------\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Split at each delimiter\n",
    "    sections = raw_answer.strip().split('---------------------------------')\n",
    "\n",
    "    for section in sections:\n",
    "        # Find the file name\n",
    "        file_match = re.search(r\"Name of the file being analyzed:\\s*(.+)\", section)\n",
    "        if not file_match:\n",
    "            continue  # skip malformed blocks\n",
    "\n",
    "        file_name = file_match.group(1).strip()\n",
    "        safe_name = sanitize_filename(file_name)\n",
    "        file_path = os.path.join(output_dir, f\"{safe_name}.md\")\n",
    "\n",
    "        # Write the rest of the section to file\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"# SecureSage Security Report\\n\\n\")\n",
    "            f.write(section.strip())\n",
    "            f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0bb4f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== AGENT TURN 1 ================\n",
      "\n",
      "Agent thought:\n",
      "The user has asked for a security review of ./example_code/malicious_hack.py. Since only a single Python file is specified, and the user has not asked for a project-wide review, I will start by loading the content of this file using load_files. After that, I will examine the file contents to decide which precise tools to use next (static_analysis and parse_ast are likely choices since it's a Python file).\n",
      "\n",
      "Tool call:\n",
      "Tool: load_files\n",
      "Args: {\n",
      "  \"path\": \"./example_code/malicious_hack.py\"\n",
      "}\n",
      "\n",
      "Tool result:\n",
      "[\n",
      "  [\n",
      "    \"example_code/malicious_hack.py\",\n",
      "    \"def malicious_attack():\\n    \\\"\\\"\\\"\\n    This function is a dangerous zero-day exploit designed to destroy everything.\\n    \\\"\\\"\\\"\\n    init_hack()\\n    DESTROY_ALL()\"\n",
      "  ]\n",
      "]\n",
      "=============== AGENT TURN 2 ================\n",
      "\n",
      "Agent thought:\n",
      "The contents of example_code/malicious_hack.py reveal a Python function named malicious_attack, with calls to functions init_hack() and DESTROY_ALL(). The code is suspicious given the naming and documentation. \n",
      "\n",
      "To identify specific security issues (e.g., unsafe/unknown function execution, malicious patterns), I will:\n",
      "1. Run static_analysis on this file to identify confirmed or suspected vulnerabilities flagged by automated scanners.\n",
      "2. In parallel, I'll consider running parse_ast to further inspect if dangerous constructs are present (such as eval, exec, etc.), in case static analysis is inconclusive.\n",
      "\n",
      "For now, I will pass the content of example_code/malicious_hack.py to static_analysis.\n",
      "\n",
      "Tool call:\n",
      "Tool: static_analysis\n",
      "Args: {\n",
      "  \"code\": \"def malicious_attack():\\n    \\\"\\\"\\\"\\n    This function is a dangerous zero-day exploit designed to destroy everything.\\n    \\\"\\\"\\\"\\n    init_hack()\\n    DESTROY_ALL()\"\n",
      "}\n",
      "\n",
      "Tool result:\n",
      "[]\n",
      "=============== AGENT TURN 3 ================\n",
      "\n",
      "Agent thought:\n",
      "The static_analysis tool did not flag any issues in example_code/malicious_hack.py. This is not unexpected, as the function names and the docstring are highly suspicious, but do not themselves match patterns of built-in vulnerabilities flagged by static analyzers (e.g., use of eval, exec, or standard injection points), likely because init_hack() and DESTROY_ALL() are custom/undefined functions.\n",
      "\n",
      "However, from a manual analysis, the function names and comments suggest that this is intentionally malicious code (\"dangerous zero-day exploit\", \"DESTROY_ALL\") and the function calls could be tied to custom/imported dangerous implementations, even if not flagged by the scanners.\n",
      "\n",
      "To confirm whether constructs like eval, exec, or command execution are used, or if other risky patterns exist, I'll also parse the code's AST for potentially dangerous function calls and usage patterns. Passing the same code to parse_ast for further analysis.\n",
      "\n",
      "Tool call:\n",
      "Tool: parse_ast\n",
      "Args: {\n",
      "  \"code\": \"def malicious_attack():\\n    \\\"\\\"\\\"\\n    This function is a dangerous zero-day exploit designed to destroy everything.\\n    \\\"\\\"\\\"\\n    init_hack()\\n    DESTROY_ALL()\"\n",
      "}\n",
      "\n",
      "Tool result:\n",
      "{\n",
      "  \"functions\": [\n",
      "    \"malicious_attack\"\n",
      "  ],\n",
      "  \"risky_calls\": [],\n",
      "  \"imports\": []\n",
      "}\n",
      "=============== AGENT TURN 4 ================\n",
      "Report written to markdown.\n"
     ]
    }
   ],
   "source": [
    "# Agent memory\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "tool_call_count = 1\n",
    "max_turns = 11\n",
    "\n",
    "tool_registry = {\n",
    "    \"load_files\": load_files,\n",
    "    \"static_analysis\": static_analysis,\n",
    "    \"parse_ast\": parse_ast,\n",
    "    \"doc_search_with_brave\": doc_search_with_brave,\n",
    "    \"suggest_fix\": suggest_fix,\n",
    "    \"check_dependencies\": check_dependencies\n",
    "}\n",
    "\n",
    "\n",
    "user_input = f\"Please analyze {CODE_PATH} for vulnerabilities.\"\n",
    "messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "file_name = os.path.basename(CODE_PATH).replace(\".py\", \"\")\n",
    "\n",
    "while tool_call_count < max_turns:\n",
    "    print(f\"=============== AGENT TURN {tool_call_count} ================\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    thought = parse_thinking_from_response(reply)\n",
    "    if thought:\n",
    "        print(\"\\nAgent thought:\")\n",
    "        print(thought)\n",
    "\n",
    "    answer = parse_answer_from_response(reply)\n",
    "    if answer:\n",
    "        split_and_write_answers(answer)\n",
    "        print(\"Report written to markdown.\")\n",
    "        break\n",
    "\n",
    "    tool_call = parse_tool_from_response(reply)\n",
    "    if not tool_call:\n",
    "        print(\"No tool call found. Exiting. Last response:\")\n",
    "        print(reply)\n",
    "        break\n",
    "\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    args = tool_call[\"args\"]\n",
    "\n",
    "    print(\"\\nTool call:\")\n",
    "    print(f\"Tool: {tool_name}\")\n",
    "    print(f\"Args: {json.dumps(args, indent=2)}\")\n",
    "\n",
    "    tool_func = tool_registry.get(tool_name)\n",
    "    if not tool_func:\n",
    "        print(f\"Unknown tool: {tool_name}\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        result = tool_func(**args)\n",
    "    except Exception as e:\n",
    "        result = {\"error\": str(e)}\n",
    "\n",
    "    print(\"\\nTool result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(result, indent=2)})\n",
    "    tool_call_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2195137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
